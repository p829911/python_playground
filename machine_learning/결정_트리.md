### 트리의 특성 중요도 (feature importance)

- 이 값은 0과 1 사이의 숫자로, 각 특성에 대해 0은 전혀 사용되지 않았다는 뜻이고 1은 완벽하게 타깃 클래스를 예측했다는 뜻이다. 특성 중요도의 전체 합은 1이다.
- 어떤 특성의 feature_importance_ 값이 낮다고 해서 이 특성이 유용하지 않다는 뜻은 아니다. 단지 트리가 그 특성을 선택하지 않았을 뿐이며 다른 특성이 동일한 정보를 지니고 있어서일 수 있다.
- 선형 모델의 계수와는 달리, 특성 중요도는 항상 양수이며 특성이 어떤 클래스를 지지하는지는 알 수 없다. 
- 트리 모델은 훈련 데이터 밖의 새로운 데이터를 예측할 능력이 없다. (트리 모델이 시계열 데이터엔 잘 맞지 않는다.)



### 장단점과 매개변수

- 매개변수
  - 사전 가지치기 매개변수
    - `max_depth` , `max_leaf_nodes` , `min_samples_leaf` 중 하나만 지정해도 과대적합을 막는 데 충분하다.
    - `max_leaf_nodes` : 리프 노드의 최대 개수를 지정하는 매개변수
    - `min_samples_leaf` : 리프 노드가 되기 위한 최소한의 샘플 개수를 지정한다
- 장단점
  - 만들어진 모델을 쉽게 시각화 할 수 있어서 비전문가도 이해하기 쉽다.
  - 데이터의 스케일에 구애받지 않는다.
    - 각 특성이 개별적으로 처리되어 데이터를 분할하는데 데이터 스케일의 영향을 받지 않으므로 결정 트리에서는 특성의 정규화나 표준화 같은 전처리 과정이 필요 없다.
    - 특성의 스케일이 서로 다르거나 이진 특성과 연속적인 특성이 혼합되어 있을 때도 잘 작동한다.
  - 사전 가지치기를 사용함에도 불구하고 과대적합되는 경향이 있어 일반화 성능이 좋지 않다.



### 결정 트리의 앙상블

- 앙상블(ensemble)은 여러 머신러닝 모델을 연결하여 더 강력한 모델을 만드는 기법이다.
- 랜덤 포레스트(random forest)와 그래디언트 부스팅(gradient boosting) 결정 트리는 둘 다 모델을 구성하는 기본 요소로 결정 트리를 사용한다.



#### 랜덤 포레스트

- 랜덤 포레스트는 기본적으로 조금씩 다른 여러 결정 트리의 묶음이다.
- 잘 작동하되 서로 다른 방향으로 과대적합된 트리를 많이 만들면 그 결과를 평균냄으로써 과대적합된 양을 줄일 수 있다.
- 각각의 트리는 타깃 예측을 잘 해야 하고 다른 트리와는 구별되어야 한다.
- 랜덤 포레스트는 이름에서 알 수 있듯이 트리들이 달라지도록 트리 생성 시 무작위성을 주입한다.
- 랜덤 포레스트에서 트리를 랜덤하게 만드는 방법은 두 가지 이다. 트리를 만들 때 사용하는 데이터 포인트를 무작위로 선택하는 방법과 분할 테스트에서 특성을 무작위로 선택하는 방법이다.